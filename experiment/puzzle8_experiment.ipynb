{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fccfb6f4-2323-4b8f-b16d-ff22ef77cd3b",
   "metadata": {},
   "source": [
    "# Experiment\n",
    "\n",
    "## Introduction\n",
    "\n",
    "1. Generate a random solvable state and define the goal state.\n",
    "2. Implement A\\* search with the two heuristics.\n",
    "3. Run 100 random tests for each heuristic.\n",
    "4. Measure memory usage (expanded nodes) and runtime.\n",
    "5. Compute mean and standard deviation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4bc9201-c58a-4392-a2af-e1a6c59d766b",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import psutil\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "from puzzle.board import Board\n",
    "from puzzle.solver import Solver\n",
    "from puzzle.heuristics import manhattan_distance, hamming_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60111806-81cc-4826-b7fb-4e2d5b2b1dd4",
   "metadata": {},
   "source": [
    "## Measure Performance\n",
    "\n",
    "Measures the performance of solving the 8-puzzle using a specified heuristic.\n",
    "\n",
    "This function calculates the computation time and memory usage required to solve the puzzle using the given heuristic. It initializes the solver with the provided board and heuristic, executes the solver and then measures the time taken and memory consumed during the process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61ce00cb-5fb4-4c44-8356-4e0be043916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_performance(heuristic, board):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    heuristic (function): The heuristic function to be used (e.g., manhattan_distance, hamming_distance).\n",
    "    board (Board): The current state of the 8-puzzle board.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the computation time (in seconds) and memory usage (in bytes).\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    process = psutil.Process()\n",
    "    initial_memory = process.memory_info().rss\n",
    "\n",
    "    solver = Solver(board, heuristic)\n",
    "    solver.solve()\n",
    "\n",
    "    end_time = time.time()\n",
    "    final_memory = process.memory_info().rss\n",
    "\n",
    "    computation_time = end_time - start_time\n",
    "    memory_usage = final_memory - initial_memory\n",
    "\n",
    "    return computation_time, memory_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19500d13-1b59-422d-8fce-9c0d55155372",
   "metadata": {},
   "source": [
    "## Run Experiment\n",
    "\n",
    "The `run_experiment` function performs the following tasks:\n",
    "\n",
    "1. Initializes a dictionary to store the results for two heuristics: `manhattan_distance` and `hamming_tiles`.\n",
    "2. Runs 100 iterations where:\n",
    "   - A random solvable 8-puzzle board is generated.\n",
    "   - The performance (computation time and memory usage) of solving the puzzle using the `manhattan_distance` heuristic is measured and recorded.\n",
    "   - The performance (computation time and memory usage) of solving the puzzle using the `hamming_distance` heuristic is measured and recorded.\n",
    "3. Returns the results as a dictionary containing the recorded times and memory usages for both heuristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "075695da-3539-4802-aba1-adbd254bc6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment():\n",
    "    results = {\n",
    "        'manhattan_distance': {'time': [], 'memory': []},\n",
    "        'hamming_distance': {'time': [], 'memory': []}\n",
    "    }\n",
    "\n",
    "    for _ in range(100):\n",
    "        board = Board.generate_random()\n",
    "\n",
    "        time_md, memory_md = measure_performance(manhattan_distance, board)\n",
    "        results['manhattan_distance']['time'].append(time_md)\n",
    "        results['manhattan_distance']['memory'].append(memory_md)\n",
    "\n",
    "        time_mt, memory_mt = measure_performance(hamming_distance, board)\n",
    "        results['misplaced_tiles']['time'].append(time_mt)\n",
    "        results['misplaced_tiles']['memory'].append(memory_mt)\n",
    "\n",
    "    return results## Summarize Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6104e0a1-1781-4e8d-82db-3dad9cf2cecd",
   "metadata": {},
   "source": [
    "## Summarize Results\n",
    "\n",
    "The `summarize_results` function calculates the average computation time and memory usage for each heuristic over 100 iterations. It processes the results obtained from the `run_experiment` function and returns a summary dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2c7543b-1322-4297-a141-e36a83fb6e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results(results):\n",
    "    \"\"\"\n",
    "    :param results: dict containing the recorded times and memory usages for both heuristics.\n",
    "    :return: dict containing the average computation time and memory usage for each heuristic.\n",
    "    \"\"\"\n",
    "    summary = {\n",
    "        'manhattan_distance': {\n",
    "            'avg_time': sum(results['manhattan_distance']['time']) / 100,\n",
    "            'avg_memory': sum(results['manhattan_distance']['memory']) / 100\n",
    "        },\n",
    "        'misplaced_tiles': {\n",
    "            'avg_time': sum(results['misplaced_tiles']['time']) / 100,\n",
    "            'avg_memory': sum(results['misplaced_tiles']['memory']) / 100\n",
    "        }\n",
    "    }\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674001e8-a6c7-4304-81e0-92b6d16fbf87",
   "metadata": {},
   "source": [
    "## Display Results\n",
    "\n",
    "The `display_results` function prints a summary table of the average computation time and memory usage for each heuristic. It uses the `tabulate` library to format the table in a grid layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "657fc492-8e2f-44da-9ae2-867550b87d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(summary):\n",
    "    \"\"\"\n",
    "    :param summary: dict containing the average computation time and memory usage for each heuristic.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    table = [\n",
    "        [\"Heuristic\", \"Avg. Computation Time (s)\", \"Avg. Memory Usage (bytes)\"],\n",
    "        [\"Manhattan Distance\", summary['manhattan_distance']['avg_time'], summary['manhattan_distance']['avg_memory']],\n",
    "        [\"Misplaced Tiles\", summary['misplaced_tiles']['avg_time'], summary['misplaced_tiles']['avg_memory']]\n",
    "    ]\n",
    "    print(tabulate(table, headers=\"firstrow\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ce7a01-b43c-4f34-8974-20a7726d3c92",
   "metadata": {},
   "source": [
    "## Visualize Results\n",
    "\n",
    "The `visualize_results` function creates a visual comparison of the average computation time and memory usage for each heuristic. It uses the matplotlib library to generate a bar chart and a line plot on the same figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36eb82da-67ee-4755-8a76-5ae5846b2962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(summary):\n",
    "    \"\"\"\n",
    "    :param summary: dict containing the average computation time and memory usage for each heuristic.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    heuristics = [\"Manhattan Distance\", \"Misplaced Tiles\"]\n",
    "    avg_times = [summary['manhattan_distance']['avg_time'], summary['misplaced_tiles']['avg_time']]\n",
    "    avg_memory = [summary['manhattan_distance']['avg_memory'], summary['misplaced_tiles']['avg_memory']]\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax1.set_xlabel('Heuristic')\n",
    "    ax1.set_ylabel('Avg. Computation Time (s)', color=color)\n",
    "    ax1.bar(heuristics, avg_times, color=color, alpha=0.6)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    color = 'tab:red'\n",
    "    ax2.set_ylabel('Avg. Memory Usage (bytes)', color=color)\n",
    "    ax2.plot(heuristics, avg_memory, color=color, marker='o')\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.title('Heuristic Performance Comparison')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24bfac0f-c4d7-42bb-af65-2fd297772cc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Board' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m summary \u001b[38;5;241m=\u001b[39m summarize_results(results)\n\u001b[1;32m      3\u001b[0m display_results(summary)\n",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m      8\u001b[0m     board \u001b[38;5;241m=\u001b[39m Board\u001b[38;5;241m.\u001b[39mgenerate_random()\n\u001b[0;32m---> 10\u001b[0m     time_md, memory_md \u001b[38;5;241m=\u001b[39m \u001b[43mmeasure_performance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmanhattan_distance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboard\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmanhattan_distance\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(time_md)\n\u001b[1;32m     12\u001b[0m     results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmanhattan_distance\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmemory\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(memory_md)\n",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m, in \u001b[0;36mmeasure_performance\u001b[0;34m(heuristic, board)\u001b[0m\n\u001b[1;32m     12\u001b[0m initial_memory \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mmemory_info()\u001b[38;5;241m.\u001b[39mrss\n\u001b[1;32m     14\u001b[0m solver \u001b[38;5;241m=\u001b[39m Solver(board, heuristic)\n\u001b[0;32m---> 15\u001b[0m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     18\u001b[0m final_memory \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mmemory_info()\u001b[38;5;241m.\u001b[39mrss\n",
      "File \u001b[0;32m~/Documents/FH/3_semester/Intro_AI_and_DS/Exercises/exercise1/puzzle/solver.py:106\u001b[0m, in \u001b[0;36mSolver.solve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m closed_set\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mtuple\u001b[39m, current_node\u001b[38;5;241m.\u001b[39mboard\u001b[38;5;241m.\u001b[39mget_state())))\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m neighbor \u001b[38;5;129;01min\u001b[39;00m get_neighbors(current_node\u001b[38;5;241m.\u001b[39mboard):\n\u001b[0;32m--> 106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbor\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01min\u001b[39;00m closed_set:\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     g \u001b[38;5;241m=\u001b[39m current_node\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Board' object is not iterable"
     ]
    }
   ],
   "source": [
    "results = run_experiment()\n",
    "summary = summarize_results(results)\n",
    "display_results(summary)\n",
    "visualize_results(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4de8ea0-9fe4-45f3-a929-e74ddb1fa05c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
